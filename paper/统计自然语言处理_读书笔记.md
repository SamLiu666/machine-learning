# 绪论

第1章至第9章主要介绍统计自然语言处理的理论，第10章至第15章主要介绍统计自然语言处理的应用。

- 在统计自然语言处理的理论方面，首先介绍有关的基础知识，例如，概率论和信息论的基本概念、形式语言和自动机的基本概念。
- 分别介绍了统计机器翻译、语音翻译、文本分类、信息检索与问答系统、信息抽取、口语信息处理与人机对话系统等各种应用系统中的统计自然语言处理方法。

本书讲述的是统计自然语言处理的经验主义方法，不要忘记在自然语言处理中还存在着另外一个方面，这就是基于规则的理性主义方法，我们也应当学习这些基于规则的理性主义方法，并且把这两种方法结合起来，彼此取长补短，使之相得益彰。

## 中文信息处理

- 汉字信息处理
- 汉语信息处理

困境： 歧义消解（disambiguation）

基本方法：

- 理性主义（rationalist）：建立符号处理系统
- 经验主义（empiricist）：通过语料库刻画真实的语言

# 概念、工具、数据

## 2 预备知识

最大似然估计（maximum likelihood estimation）：用相对频率作为概率的估计值

贝叶斯决策理论：似然比 $l(x) =\frac{p(x|w_1)}{p(x|w_2)} >\frac{P(w_2)}{p(w_1)}$ 则 $x\in{w_1}$， 否则 $x\in{w_2}$

熵：描述一个随机变量的不确定性的数量，越大约不确定熵最大的情况真实反映了时间的分布情况 $H(D) = - \sum_{k=1}^k \frac{|C_k|}{|D|} log_2 \frac{|C_k|}{|D|} = -\sum_{k=1}^{k} {p(x)}log_2 {p(x)} $  ， 则

$$ \hat{p} = argmax_{p\in{C}}H(p)$$

联合熵：一对随机变量平均所需的信息量

 $H(X,Y) = -\sum_{x\in{X}}\sum_{y\in{Y}}p(x,y)log{p(x,y)}$

熵连锁规则： $H(X_1,X_2,...,X_n)= H(X_1) + H(X_2|X_1)+..+H(X_n|X_1,..X_{n-1}) $

互信息：词汇聚类，汉语分词，$I(X;Y)$理解为Y的值透露了多少关于X的信息量

相对熵:（relative entropy）又称Kullback-Leibler差异（Kullback-Leibler divergence），或简称KL距离，是衡量相同事件空间里两个概率分布相对差距的测度。当两个随机分布的差别增加时，其相对熵期望值也增大

交叉熵:交叉熵的概念就是用来衡量估计模型与真实概率分布之间差异情况的。 交叉熵越小，模型表现越好

困惑度：通常用困惑度（perplexity）来代替交叉熵衡量语言模型的好坏

噪声信道模型：如何定量地估算从信道输出中获取多少信息量。

### 支持向量机

SVM- Support Vector Machine ：短语识别，语义消歧，文本自动分类，信息过滤等

- 线性分类
  - 如果训练数据可以被无误差地划分，那么，以最大间隔分开数据的超平面称为最优超平面
  - $f(x) = <w {x}> + b= \sum_{i=1}^{n}w_ix_i + b$
  - $c(x) = argmax_{1<=i<=m}(<w_i x> + b_i)$  - 多分类问题
- 线性不可分
  - $f(x) = \sum_{i=1}^{i}a_iy_i<\Theta(x)\Theta(x)> + b$
  - $<\Theta(x)\Theta(x)>$ 为核函数

## 3 形式语言与自动机

### 基本概念

- 图分为有向图、无向图、连通图、回路
- 森林：一个无回路的无向图
- 树：一个无回路的连通无向图，结点被特别标记为根结点则成为根树
- 字符串
- 语言：按照一定规律构成的句子和符号的集合

形式语法是一个四元组G＝（N，Σ，P，S），其中，N是非终结符（non-terminal symbol）的有限集合（有时也称变量集或句法种类集）；Σ是终结符号（terminal symbol）的有限集合，N∩Σ＝∅；V＝N∪Σ称为总词汇表（vocabulary）；P是一组重写规则的有限集合：P＝{α→β}，其中，α，β是由V中元素构成的串，但是，α中至少应含有一个非终结符号；S∈N称为句子符或初始符。

### CFG识别句子派生树

派生树也称语法树（syntactic tree），或分析树（parsing tree）、推导树

## 4 语料库与语言知识库

- LDC 中文树库
- 语言知识库
  - WordNet：英语词汇知识资源库
  - FrameNet：基于框架语义学（frame semantics）
  - EDR：面向自然语言处理的词典
  - 北京大学综合型语言知识库（CLKB）：“属性—属性值”
  - 知网（HowNet）

### 语言知识库与本体论

本体：一个逻辑理论的陈述性描述，可理解为描述特定领域概念的知识库

本体论（ontology）： 一个逻辑理论

概念化（conceptualization）是知识形式化表达的基础，是所关心领域中的对象、概念和其他实体，以及它们之间的关系。

自动本体构建：

1. 确定领域中的概念集合，术语抽取是构建本体的必要预处理步骤

2. 关系发现：识别和提取概念之间的关系，也称属性发现

## 5 语言模型

Language model(LM):  本书主要介绍N-元模型和几种平滑处理方式

- 当n＝1时，即出现在第i位上的词wi独立于历史时，一元文法被记作unigram，或uni-gram，或monogram；
- 当n＝2时，即出现在第i位上的词wi仅与它前面的一个历史词wi-1有关，二元文法模型被称为一阶马尔可夫链（Markov chain），记作bigram或bi-gram；
- 当n＝3时，即出现在第i位置上的词wi仅与它前面的两个历史词wi-2wi-1有关，三元文法模型被称为二阶马尔可夫链，记作trigram或tri-gram。

二元语法为例：

$$P(s) = \prod_{i=1}^l {p(w_i|w_1,w_2..w_{i-1})} = \prod_{i=1}^{l} {p(w_i | w_{i-1})}$$

数据平滑处理方法：

1. 加法平滑处理
2. 古德-图灵估计法
3. Katz 平滑处理
4. Jelinek-Mercer平滑方法

## 6 概率图模型

动态贝叶斯网络（dynamic Bayesian networks, DBN）用于处理随时间变化的动态系统中的推断和预测问题隐。

马尔可夫模型（hidden Markov model, HMM）在语音识别、汉语自动分词与词性标注和统计机器翻译等若干语音语言处理任务中得到了广泛应用；卡尔曼滤波器则在信号处理领域有广泛的用途。

马尔可夫网络（Markovnetwork）又称马尔可夫随机场（Markov random field, MRF）。马尔可夫网络下的条件随机场（conditional random field, CRF）广泛应用于自然语言处理中的序列标注、特征选择、机器翻译等任务，波尔兹曼机（Boltzmann machine）近年来被用于依存句法分析和语义角色标注等。

### 贝叶斯网络

贝叶斯网络就是一个有向无环图（directed acyclicgraph, DAG），结点表示随机变量，可以是可观测量、隐含变量、未知参量或假设等。

### 马尔可夫模型

序列---序列  HMM 隐马尔可夫模型

HMM 参数估计：期望最大化（expectation maximization, EM）算法可以用于含有隐变量的统计模型的参数最大似然估计

### 最大熵模型

### 条件随机场（conditional random fields, CRFs）

## 7 自动分词、命名实体识别与词性标注

汉语自动分词的主要困难来自如下三个方面：分词规范、歧义切分和未登录词的识别

### 汉语分词方法

基于统计模型的分词方法，并对这些分词技术进行简要的比较。

- N-最短路径方法
- 基于词的n元语法模型的分词方法
- 由字构词的汉语分词方法
- 基于词感知机算法的汉语分词方法

### 命名实体识别

- 基于CRF的命名实体识别方法
- 基于多特征的命名实体识别方法

### 词性标注

- 基于统计模型的词性标注方法
- 基于规则的词性标注方法
- 统计方法与规则方法相结合的词性标注方法

## 8 句法分析

语法结构分析方法：

- 基于规则的分析方法：诸多的局限性
- 基于统计的分析方法
- 

# 关键技术

# 应用系统

