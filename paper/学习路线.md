# 参考

https://github.com/zibuyu/research_tao

# NLP 学术界

自然语言处理（Natural Language Processing，NLP）在很大程度上与计算语言学（Computational Linguistics，CL）重叠，最权威的会议：The Association for Computational Linguistics--ACL

International Conference on Computational Linguistics（COLING） 

[ACL 主页](https://www.aclweb.org/anthology/) 论文可以免费下载浏览    [ARXIV](https://arxiv.org/)  发文最快速的地方，需要自己有较强的鉴别力

人工智能领域相关学术会议包括IJCAI和AAAI

# 通过论文掌握学术动态

打好基础：概率论，人工智能，机器学习、数据结构等等

## Google Scholar

面向特定主题的文献选择：

- 按作者搜索：author:"DM Blei"，可以搜索指定作者的相关论文；
- 按发表期刊/会议搜索：source:"Nature"，可以搜索发表在指定期刊/会议的相关论文；
- 按标题出现关键词搜索：allintitle:"latent dirichlet allocation"，可以搜索在标题出现某些关键词的论文；
- 搜索引擎常用的and、or和""均支持，其中""表示按引号中的字符串完整搜索。

查阅综述：一篇该领域的最新研究综述

- 可以在中文知网（CNKI）中搜索"课题名称+综述"
- Google Scholar中搜索“课题名称 + survey / review / tutorial / 综述”来查找

## 文献选择能力

- arXiv.org 上定期发布的论文；
- 相关国际顶级会议每年发表的论文集；
- 相关国际顶级期刊定期发表的论文；
- 国际顶尖高校研究组或企业研究机构发布的新闻或学术报告；
- 科技媒体和社交媒体集中报道或讨论的学术成果；等等。

工作是否值得关注：

- 论文的作者是否为该领域的著名学者，研究机构是否来自业内顶尖。
- 论文是否发表在顶级期刊/会议上。
- 论文社会关注度如何，是否获得最佳论文，引用情况如何。

# 如何阅读文献

阅读论文也不必需要每篇都从头到尾看完。一篇学术论文通常包括以下结构，我们用序号来标记建议的阅读顺序：

- 题目（1）
- 摘要（2）
- 正文：导论（3）、相关工作（6）、本文工作（5）、实验结果（4）、结论（7）
- 参考文献（6）
- 附录

按照这个顺序，基本在读完题目和摘要后，大致可以判断这篇论文与自己研究课题的相关性，然后就可以决定是否要精读导论和实验结果判断学术价值，是否阅读本文工作了解方法细节。此外，如果希望了解相关工作和未来工作，则可以有针对性地阅读“相关工作”和“结论”等部分。

社交媒体：微博或知乎中的用户搜索中检索“自然语言处理”、“计算语言学”、“信息检索”、“机器学习”等

# 好的研究想法

学科发展角度：开展创新研究，就是要提出新的想法解决这些问题。这其中的”新“字，可以体现在提出新的问题和任务，探索新的解决思路，提出新的算法技术，实现新的工具系统等。

研究实践角度：只有**能做得出来的想法**才有资格被分析好不好。所以，从研究实践角度，还需要考虑研究想法的**可实现性**和**可验证性**

要有区分研究想法好与不好的能力，这需要**深入全面了解所在研究方向的历史与现状**，具体就是对学科文献的全面掌握。人是最善于学习的动物，完全可以将既有文献中不同时期研究工作的想法作为学习对象，通过了解它们提出后对学科发展的影响——具体体现在论文引用、学术评价情况等各方面——建立对研究想法好与不好的评价模型。

- **实践法**： 算法复杂度 效率上的考虑
- **类比**：将研究问题与其他任务建立类比联系，调研其他相似任务上最新的有效思想、算法或工具，通过合理的转换迁移，运用到当前的研究问题上来。
- **组合**：将新的研究问题分解为若干已被较好解决的子问题，通过有机地组合这些子问题上的最好做法，建立对新的研究问题的解决方案

对于初学者而言，一开始就想清楚五年的研究计划，根本不可能。但想，还是不去想，结果还是不同的。

研究难点：提前考虑，哪些问题是纯数据驱动技术无法解决的。NLP和AI中的困难任务，如常识和知识推理，复杂语境和跨模态理解，可解释智能，都还没有可行的解决方案，我个人也不看好数据驱动方法能够彻底解决。更高层次的联想、创造、顿悟等认知能力，更是连边还没碰到。这些正是有远见的研究者们应该开始关注的方向。