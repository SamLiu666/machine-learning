{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dtype = torch.FloatTensor\n",
    "# S: Symbol that shows starting of decoding input\n",
    "# E: Symbol that shows starting of decoding output\n",
    "# P: Symbol that will fill in blank sequence if current batch data size is short than time steps\n",
    "sentences = ['ich mochte ein bier P', 'S i want a beer', 'i want a beer E']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = \" \".join(sentences).split()\n",
    "word_list = list(set(word_list))\n",
    "word_dict = {w: i for i, w in enumerate(word_list)}\n",
    "number_dict = {i: w for i, w in enumerate(word_list)}\n",
    "n_class = len(word_dict)  # vocab list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter\n",
    "n_hidden = 128\n",
    "\n",
    "def make_batch(sentences):\n",
    "    input_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[0].split()]]]\n",
    "    output_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[1].split()]]]\n",
    "    target_batch = [[word_dict[n] for n in sentences[2].split()]]\n",
    "\n",
    "    # make tensor\n",
    "    return Variable(torch.Tensor(input_batch)), Variable(torch.Tensor(output_batch)), Variable(torch.LongTensor(target_batch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention, self).__init__()\n",
    "        self.enc_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5)\n",
    "        self.dec_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5)\n",
    "\n",
    "        # Linear for attention\n",
    "        self.attn = nn.Linear(n_hidden, n_hidden)\n",
    "        self.out = nn.Linear(n_hidden * 2, n_class)\n",
    "\n",
    "    def forward(self, enc_inputs, hidden, dec_inputs):\n",
    "        enc_inputs = enc_inputs.transpose(0, 1)  # enc_inputs: [n_step(=n_step, time step), batch_size, n_class]\n",
    "        dec_inputs = dec_inputs.transpose(0, 1)  # dec_inputs: [n_step(=n_step, time step), batch_size, n_class]\n",
    "\n",
    "        # enc_outputs : [n_step, batch_size, num_directions(=1) * n_hidden], matrix F\n",
    "        # enc_hidden : [num_layers(=1) * num_directions(=1), batch_size, n_hidden]\n",
    "        enc_outputs, enc_hidden = self.enc_cell(enc_inputs, hidden)\n",
    "\n",
    "        trained_attn = []\n",
    "        hidden = enc_hidden\n",
    "        n_step = len(dec_inputs)\n",
    "        model = Variable(torch.empty([n_step, 1, n_class]))\n",
    "\n",
    "        for i in range(n_step):  # each time step\n",
    "            # dec_output : [n_step(=1), batch_size(=1), num_directions(=1) * n_hidden]\n",
    "            # hidden : [num_layers(=1) * num_directions(=1), batch_size(=1), n_hidden]\n",
    "            dec_output, hidden = self.dec_cell(dec_inputs[i].unsqueeze(0), hidden)\n",
    "            attn_weights = self.get_att_weight(dec_output, enc_outputs)  # attn_weights : [1, 1, n_step]\n",
    "            trained_attn.append(attn_weights.squeeze().data.numpy())\n",
    "\n",
    "            # matrix-matrix product of matrices [1,1,n_step] x [1,n_step,n_hidden] = [1,1,n_hidden]\n",
    "            context = attn_weights.bmm(enc_outputs.transpose(0, 1))\n",
    "            dec_output = dec_output.squeeze(0)  # dec_output : [batch_size(=1), num_directions(=1) * n_hidden]\n",
    "            context = context.squeeze(1)  # [1, num_directions(=1) * n_hidden]\n",
    "            model[i] = self.out(torch.cat((dec_output, context), 1))\n",
    "\n",
    "        # make model shape [n_step, n_class]\n",
    "        return model.transpose(0, 1).squeeze(0), trained_attn\n",
    "\n",
    "    def get_att_weight(self, dec_output, enc_outputs):  # get attention weight one 'dec_output' with 'enc_outputs'\n",
    "        n_step = len(enc_outputs)\n",
    "        attn_scores = Variable(torch.zeros(n_step))  # attn_scores : [n_step]\n",
    "\n",
    "        for i in range(n_step):\n",
    "            attn_scores[i] = self.get_att_score(dec_output, enc_outputs[i])\n",
    "\n",
    "        # Normalize scores to weights in range 0 to 1\n",
    "        return F.softmax(attn_scores).view(1, 1, -1)\n",
    "\n",
    "    def get_att_score(self, dec_output, enc_output):  # enc_outputs [batch_size, num_directions(=1) * n_hidden]\n",
    "        score = self.attn(enc_output)  # score : [batch_size, n_hidden]\n",
    "        return torch.dot(dec_output.view(-1), score.view(-1))  # inner product make scalar value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0400 cost = 0.000501\n",
      "Epoch: 0800 cost = 0.000160\n",
      "Epoch: 1200 cost = 0.000079\n",
      "Epoch: 1600 cost = 0.000047\n",
      "Epoch: 2000 cost = 0.000030\n"
     ]
    }
   ],
   "source": [
    "input_batch, output_batch, target_batch = make_batch(sentences)\n",
    "\n",
    "# hidden : [num_layers(=1) * num_directions(=1), batch_size, n_hidden]\n",
    "hidden = Variable(torch.zeros(1, 1, n_hidden))\n",
    "\n",
    "model = Attention()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train\n",
    "for epoch in range(2000):\n",
    "    optimizer.zero_grad()\n",
    "    output, _ = model(input_batch, hidden, output_batch)\n",
    "\n",
    "    loss = criterion(output, target_batch.squeeze(0))\n",
    "    if (epoch + 1) % 400 == 0:\n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ich mochte ein bier P -> ['i', 'want', 'a', 'beer', 'E']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "test_batch = [np.eye(n_class)[[word_dict[n] for n in 'SPPPP']]]\n",
    "test_batch = Variable(torch.Tensor(test_batch))\n",
    "predict, trained_attn = model(input_batch, hidden, test_batch)\n",
    "predict = predict.data.max(1, keepdim=True)[1]\n",
    "print(sentences[0], '->', [number_dict[n.item()] for n in predict.squeeze()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show Attention\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.matshow(trained_attn, cmap='viridis')\n",
    "ax.set_xticklabels([''] + sentences[0].split(), fontdict={'fontsize': 14})\n",
    "ax.set_yticklabels([''] + sentences[2].split(), fontdict={'fontsize': 14})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
