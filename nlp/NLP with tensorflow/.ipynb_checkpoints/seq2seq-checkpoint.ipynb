{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ops' from 'tensorflow.keras' (D:\\Anaconda\\envs\\tensorflow2.0\\lib\\site-packages\\tensorflow\\python\\keras\\api\\_v2\\keras\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-5017f158d0d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable_v2_behavior\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'ops' from 'tensorflow.keras' (D:\\Anaconda\\envs\\tensorflow2.0\\lib\\site-packages\\tensorflow\\python\\keras\\api\\_v2\\keras\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "        \n",
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import ops\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training examples : \n",
      "(15, 3, 1)\n",
      "(seq_length, batch_size, output_dim)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'placeholder'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-773ffbe97e3d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[0mdecode_input\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0mencoder_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[0mexpected_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0mdecode_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
     ]
    }
   ],
   "source": [
    "def do_generate_x_y(isTrain, batch_size, seqlen):\n",
    "    batch_x = []\n",
    "    batch_y = []\n",
    "    for _ in range(batch_size):\n",
    "        offset_rand = random.random() * 2 * math.pi\n",
    "        freq_rand = (random.random() - 0.5) / 1.5 * 15 + 0.5\n",
    "        amp_rand = random.random() + 0.1\n",
    "\n",
    "        sin_data = amp_rand * np.sin(np.linspace(\n",
    "            seqlen / 15.0 * freq_rand * 0.0 * math.pi + offset_rand,\n",
    "            seqlen / 15.0 * freq_rand * 3.0 * math.pi + offset_rand, seqlen * 2)  )\n",
    "\n",
    "        offset_rand = random.random() * 2 * math.pi\n",
    "        freq_rand = (random.random() - 0.5) / 1.5 * 15 + 0.5\n",
    "        amp_rand = random.random() * 1.2\n",
    "\n",
    "        sig_data = amp_rand * np.cos(np.linspace(\n",
    "            seqlen / 15.0 * freq_rand * 0.0 * math.pi + offset_rand,\n",
    "            seqlen / 15.0 * freq_rand * 3.0 * math.pi + offset_rand, seqlen * 2)) + sin_data\n",
    "\n",
    "        batch_x.append(np.array([ sig_data[:seqlen] ]).T)\n",
    "        batch_y.append(np.array([ sig_data[seqlen:] ]).T)\n",
    "\n",
    "    # shape: (batch_size, seq_length, output_dim)\n",
    "    batch_x = np.array(batch_x).transpose((1, 0, 2))\n",
    "    batch_y = np.array(batch_y).transpose((1, 0, 2))\n",
    "    # shape: (seq_length, batch_size, output_dim)\n",
    "\n",
    "    return batch_x, batch_y\n",
    "\n",
    "#生成15个连续序列，将con和sin随机偏移变化后的值叠加起来\n",
    "def generate_data(isTrain, batch_size):\n",
    "    seq_length =15\n",
    "    if isTrain :\n",
    "        return do_generate_x_y(isTrain, batch_size, seq_length)\n",
    "    else:\n",
    "        return do_generate_x_y(isTrain, batch_size, seq_length*2)\n",
    "    \n",
    "        \n",
    "sample_now, sample_f = generate_data(isTrain=True, batch_size=3)\n",
    "print(\"training examples : \")\n",
    "print(sample_now.shape)\n",
    "print(\"(seq_length, batch_size, output_dim)\")\n",
    "\n",
    "\n",
    "seq_length = sample_now.shape[0]\n",
    "batch_size = 10\n",
    "\n",
    "output_dim = input_dim = sample_now.shape[-1]\n",
    "hidden_dim = 12  \n",
    "layers_num = 2\n",
    "\n",
    "# Optmizer:\n",
    "learning_rate =0.04\n",
    "nb_iters = 100\n",
    "\n",
    "lambda_l2_reg = 0.003  # L2 regularization of weights - avoids overfitting\n",
    "        \n",
    "        \n",
    "ops.reset_default_graph()\n",
    "\n",
    "\n",
    "encoder_input = []\n",
    "expected_output = []\n",
    "decode_input =[]\n",
    "for i in range(seq_length):\n",
    "    encoder_input.append( tf.placeholder(tf.float32, shape=( None, input_dim)) )\n",
    "    expected_output.append( tf.placeholder(tf.float32, shape=( None, output_dim)) )\n",
    "    decode_input.append( tf.placeholder(tf.float32, shape=( None, input_dim)) )\n",
    "\n",
    "    \n",
    "tcells = []\n",
    "for i in range(layers_num):\n",
    "    tcells.append(tf.contrib.rnn.GRUCell(hidden_dim))\n",
    "Mcell = tf.contrib.rnn.MultiRNNCell(tcells)\n",
    "\n",
    "dec_outputs, dec_memory = tf.contrib.legacy_seq2seq.basic_rnn_seq2seq(encoder_input,decode_input,Mcell)\n",
    "\n",
    "reshaped_outputs = []\n",
    "for ii in dec_outputs :\n",
    "    reshaped_outputs.append( tf.contrib.layers.fully_connected(ii,output_dim,activation_fn=None))\n",
    "\n",
    "\n",
    "# L2 loss\n",
    "output_loss = 0\n",
    "for _y, _Y in zip(reshaped_outputs, expected_output):\n",
    "    output_loss += tf.reduce_mean( tf.pow(_y - _Y, 2) )\n",
    "   \n",
    "# generalization capacity)\n",
    "reg_loss = 0\n",
    "for tf_var in tf.trainable_variables():\n",
    "    if not (\"fully_connected\" in tf_var.name ):\n",
    "        #print(tf_var.name)\n",
    "        reg_loss += tf.reduce_mean(tf.nn.l2_loss(tf_var))\n",
    "\n",
    "loss = output_loss + lambda_l2_reg * reg_loss\n",
    "train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)   \n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "        \n",
    "def train_batch(batch_size):\n",
    "\n",
    "    X, Y = generate_data(isTrain=True, batch_size=batch_size)\n",
    "    feed_dict = {encoder_input[t]: X[t] for t in range(len(encoder_input))}\n",
    "    feed_dict.update({expected_output[t]: Y[t] for t in range(len(expected_output))})\n",
    "\n",
    "    c =np.concatenate(( [np.zeros_like(Y[0])],Y[:-1]),axis = 0)\n",
    "\n",
    "    feed_dict.update({decode_input[t]: c[t] for t in range(len(c))})\n",
    "\n",
    "    _, loss_t = sess.run([train_op, loss], feed_dict)\n",
    "    return loss_t\n",
    "\n",
    "\n",
    "def test_batch(batch_size):\n",
    "    X, Y = generate_data(isTrain=True, batch_size=batch_size)\n",
    "    feed_dict = {encoder_input[t]: X[t] for t in range(len(encoder_input))}\n",
    "    feed_dict.update({expected_output[t]: Y[t] for t in range(len(expected_output))})\n",
    "    c =np.concatenate(( [np.zeros_like(Y[0])],Y[:-1]),axis = 0)#来预测最后一个序列\n",
    "    feed_dict.update({decode_input[t]: c[t] for t in range(len(c))})    \n",
    "    output_lossv,reg_lossv,loss_t = sess.run([output_loss,reg_loss,loss], feed_dict)\n",
    "    print(\"-----------------\")    \n",
    "    print(output_lossv,reg_lossv)\n",
    "    return loss_t\n",
    "\n",
    "\n",
    "# Training\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for t in range(nb_iters + 1):\n",
    "    train_loss = train_batch(batch_size)\n",
    "    train_losses.append(train_loss)\n",
    "    if t % 50 == 0:\n",
    "        test_loss = test_batch(batch_size)\n",
    "        test_losses.append(test_loss)\n",
    "        print(\"Step {}/{}, train loss: {}, \\tTEST loss: {}\".format(t,nb_iters, train_loss, test_loss))\n",
    "print(\"Fin. train loss: {}, \\tTEST loss: {}\".format(train_loss, test_loss))        \n",
    "        \n",
    "        \n",
    "        \n",
    "# Plot loss over time:\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(np.array(range(0, len(test_losses))) /\n",
    "    float(len(test_losses) - 1) * (len(train_losses) - 1),\n",
    "    np.log(test_losses),label=\"Test loss\")\n",
    "    \n",
    "plt.plot(np.log(train_losses),label=\"Train loss\")\n",
    "plt.title(\"Training errors over time (on a logarithmic scale)\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('log(Loss)')\n",
    "plt.legend(loc='best')\n",
    "plt.show()        \n",
    "        \n",
    "        \n",
    "# Test\n",
    "nb_predictions = 5\n",
    "print(\"visualize {} predictions data:\".format(nb_predictions))\n",
    "\n",
    "preout =[]\n",
    "X, Y = generate_data(isTrain=False, batch_size=nb_predictions)\n",
    "print(np.shape(X),np.shape(Y))\n",
    "for tt in  range(seq_length):\n",
    "    feed_dict = {encoder_input[t]: X[t+tt] for t in range(seq_length)}\n",
    "    feed_dict.update({expected_output[t]: Y[t+tt] for t in range(len(expected_output))})\n",
    "    c =np.concatenate(( [np.zeros_like(Y[0])],Y[tt:seq_length+tt-1]),axis = 0)  #从前15个的最后一个开始预测  \n",
    "\n",
    "    feed_dict.update({decode_input[t]: c[t] for t in range(len(c))})\n",
    "    outputs = np.array(sess.run([reshaped_outputs], feed_dict)[0])\n",
    "    preout.append(outputs[-1])\n",
    "\n",
    "print(np.shape(preout))#将每个未知预测值收集起来准备显示出来。\n",
    "preout =np.reshape(preout,[seq_length,nb_predictions,output_dim])\n",
    "\n",
    "for j in range(nb_predictions):\n",
    "    plt.figure(figsize=(12, 3))\n",
    "\n",
    "    for k in range(output_dim):\n",
    "        past = X[:, j, k]\n",
    "        expected = Y[seq_length-1:, j, k]#对应预测值的打印\n",
    "\n",
    "        pred = preout[:, j, k]\n",
    "\n",
    "        label1 = \"past\" if k == 0 else \"_nolegend_\"\n",
    "        label2 = \"future\" if k == 0 else \"_nolegend_\"\n",
    "        label3 = \"Pred\" if k == 0 else \"_nolegend_\"\n",
    "        plt.plot(range(len(past)), past, \"o--b\", label=label1)\n",
    "        plt.plot(range(len(past), len(expected) + len(past)),\n",
    "                 expected, \"x--b\", label=label2)\n",
    "        plt.plot(range(len(past), len(pred) + len(past)),\n",
    "                 pred, \"o--y\", label=label3)\n",
    "\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(\"Predictions vs. future\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
