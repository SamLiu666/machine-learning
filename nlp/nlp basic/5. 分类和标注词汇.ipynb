{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 什么是词汇分类，在自然语言处理中它们是如何使用？\n",
    "* 一个好的存储词汇和它们的分类的Python数据结构是什么？\n",
    "* 我们如何自动标注文本中词汇的词类？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "介绍NLP的一些基本技术，包括序列标注、N-gram模型、回退和评估。这些技术在许多方面都很有用，标注为我们提供了一个表示它们的简单的上下文。我们还将看到，在典型的NLP处理流程中，标注为何是位于分词之后的第二个步骤。\n",
    "\n",
    "将单词按它们的词性分类并进行相应地标注的过程，称为词语性质标注、词性标注或简称标注。词性也称为词类或词汇类别。用于特定任务的标记的集合被称为一个标记集。我们在本章的重点是运用标记和自动标注文本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用词性标注器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('And', 'CC'),\n",
       " ('now', 'RB'),\n",
       " ('for', 'IN'),\n",
       " ('something', 'NN'),\n",
       " ('completely', 'RB'),\n",
       " ('different', 'JJ')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = word_tokenize(\"And now for something completely different\")\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and是CC，并列连词；now和completely是RB，副词；for是IN，介词；something是NN，名词；different是JJ，形容词。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('你好啊，我是大大，很开心认识你', 'NN')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = word_tokenize(\"你好啊，我是大大，很开心认识你\")\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('They', 'PRP'),\n",
       " ('refuse', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('permit', 'VB'),\n",
       " ('us', 'PRP'),\n",
       " ('to', 'TO'),\n",
       " ('obtain', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('refuse', 'NN'),\n",
       " ('permit', 'NN')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = word_tokenize(\"They refuse to permit us to obtain the refuse permit\")\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man time day year car moment world house family child country boy\n",
      "state job place way war girl work word\n"
     ]
    }
   ],
   "source": [
    "text = nltk.Text(word.lower() for word in nltk.corpus.brown.words())\n",
    "text.similar('woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fly', 'NN')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 已经标注的语料库\n",
    "tagged_token = nltk.tag.str2tuple('fly/NN')\n",
    "tagged_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'AT'),\n",
       " ('grand', 'JJ'),\n",
       " ('jury', 'NN'),\n",
       " ('commented', 'VBD'),\n",
       " ('on', 'IN'),\n",
       " ('a', 'AT'),\n",
       " ('number', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('other', 'AP'),\n",
       " ('topics', 'NNS'),\n",
       " (',', ','),\n",
       " ('AMONG', 'IN'),\n",
       " ('them', 'PPO'),\n",
       " ('the', 'AT'),\n",
       " ('Atlanta', 'NP'),\n",
       " ('and', 'CC'),\n",
       " ('Fulton', 'NP-TL'),\n",
       " ('County', 'NN-TL'),\n",
       " ('purchasing', 'VBG'),\n",
       " ('departments', 'NNS'),\n",
       " ('which', 'WDT'),\n",
       " ('it', 'PPS'),\n",
       " ('said', 'VBD'),\n",
       " ('``', '``'),\n",
       " ('ARE', 'BER'),\n",
       " ('well', 'QL'),\n",
       " ('operated', 'VBN'),\n",
       " ('and', 'CC'),\n",
       " ('follow', 'VB'),\n",
       " ('generally', 'RB'),\n",
       " ('accepted', 'VBN'),\n",
       " ('practices', 'NNS'),\n",
       " ('which', 'WDT'),\n",
       " ('inure', 'VB'),\n",
       " ('to', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('best', 'JJT'),\n",
       " ('interest', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('both', 'ABX'),\n",
       " ('governments', 'NNS'),\n",
       " (\"''\", \"''\"),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = '''\n",
    "... The/AT grand/JJ jury/NN commented/VBD on/IN a/AT number/NN of/IN\n",
    "... other/AP topics/NNS ,/, AMONG/IN them/PPO the/AT Atlanta/NP and/CC\n",
    "... Fulton/NP-tl County/NN-tl purchasing/VBG departments/NNS which/WDT it/PPS\n",
    "... said/VBD ``/`` ARE/BER well/QL operated/VBN and/CC follow/VB generally/RB\n",
    "... accepted/VBN practices/NNS which/WDT inure/VB to/IN the/AT best/JJT\n",
    "... interest/NN of/IN both/ABX governments/NNS ''/'' ./.\n",
    "... '''\n",
    "[nltk.tag.str2tuple(t) for t in sent.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'AT'), ('Fulton', 'NP-TL'), ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.brown.tagged_words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "只要语料库包含已标注的文本，NLTK的语料库接口都将有一个tagged_words()方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NOUN', 30654),\n",
       " ('VERB', 14399),\n",
       " ('ADP', 12355),\n",
       " ('.', 11928),\n",
       " ('DET', 11389),\n",
       " ('ADJ', 6706),\n",
       " ('ADV', 3349),\n",
       " ('CONJ', 2717),\n",
       " ('PRON', 2535),\n",
       " ('PRT', 2264),\n",
       " ('NUM', 2166),\n",
       " ('X', 92)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "brown_news_tagged = brown.tagged_words(categories='news', tagset='universal')\n",
    "tag_fd = nltk.FreqDist(tag for (word, tag) in brown_news_tagged)\n",
    "tag_fd.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-GRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9349006503968017"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "brown_tagged_sents = brown.tagged_sents(categories='news')\n",
    "brown_sents = brown.sents(categories='news')\n",
    "unigram_tagger = nltk.UnigramTagger(brown_tagged_sents)\n",
    "unigram_tagger.tag(brown_sents[2007])\n",
    "unigram_tagger.evaluate(brown_tagged_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8121200039868434"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = int(len(brown_tagged_sents) * 0.9)  # 训练数据和测试数据比0.9\n",
    "train_sents = brown_tagged_sents[:size]\n",
    "test_sents = brown_tagged_sents[size:]\n",
    "\n",
    "unigram_tagger = nltk.UnigramTagger(train_sents)  # 数据训练N-GRAM模型\n",
    "unigram_tagger.evaluate(test_sents)               # 测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一般标注器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Various', 'JJ'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('apartments', 'NNS'),\n",
       " ('are', 'BER'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('terrace', 'NN'),\n",
       " ('type', 'NN'),\n",
       " (',', ','),\n",
       " ('being', 'BEG'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('ground', 'NN'),\n",
       " ('floor', 'NN'),\n",
       " ('so', 'CS'),\n",
       " ('that', 'CS'),\n",
       " ('entrance', 'NN'),\n",
       " ('is', 'BEZ'),\n",
       " ('direct', 'JJ'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_tagger = nltk.BigramTagger(train_sents)\n",
    "bigram_tagger.tag(brown_sents[2007])\n",
    "tri_tagger = nltk.TrigramTagger(train_sents)\n",
    "tri_tagger.tag(brown_sents[2007])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'AT'),\n",
       " ('population', None),\n",
       " ('of', None),\n",
       " ('the', None),\n",
       " ('Congo', None),\n",
       " ('is', None),\n",
       " ('13.5', None),\n",
       " ('million', None),\n",
       " (',', None),\n",
       " ('divided', None),\n",
       " ('into', None),\n",
       " ('at', None),\n",
       " ('least', None),\n",
       " ('seven', None),\n",
       " ('major', None),\n",
       " ('``', None),\n",
       " ('culture', None),\n",
       " ('clusters', None),\n",
       " (\"''\", None),\n",
       " ('and', None),\n",
       " ('innumerable', None),\n",
       " ('tribes', None),\n",
       " ('speaking', None),\n",
       " ('400', None),\n",
       " ('separate', None),\n",
       " ('dialects', None),\n",
       " ('.', None)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_sent = brown_sents[4203]\n",
    "bigram_tagger.tag(unseen_sent)\n",
    "tri_tagger.tag(unseen_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10206319146815508"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_tagger.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0626931127279976"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tri_tagger.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二元标注器能够标注训练中它看到过的句子中的所有词，但对一个没见过的句子表现很差。只要遇到一个新词（如13.5），就无法给它分配标记。它不能标注下面的词（如million)，即使是在训练过程中看到过的，只是因为在训练过程中从来没有见过它前面有一个None标记的词。因此，标注器标注句子的其余部分也失败了。它的整体准确度得分非常低"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当n越大，上下文的特异性就会增加，我们要标注的数据中包含训练数据中不存在的上下文的几率也增大。这被称为数据稀疏问题，在NLP中是相当普遍的。因此，我们的研究结果的精度和覆盖范围之间需要有一个权衡（这与信息检索中的精度/召回权衡有关）。\n",
    "\n",
    "N-gram标注器不应考虑跨越句子边界的上下文。因此，NLTK的标注器被设计用于句子列表，其中一个句子是一个词列表。在一个句子的开始，tn-1和前面的标记被设置为None。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 组合标注\n",
    "* 尝试使用二元标注器标注标识符。\n",
    "* 如果二元标注器无法找到一个标记，尝试一元标注器。\n",
    "* 如果一元标注器也无法找到一个标记，使用默认标注器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8452108043456593"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = nltk.DefaultTagger('NN')\n",
    "t1 = nltk.UnigramTagger(train_sents, backoff=t0)\n",
    "t2 = nltk.BigramTagger(train_sents, backoff=t1)\n",
    "t2.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.843317053722715"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3 = nltk.TrigramTagger(train_sents, backoff=t2)\n",
    "t3.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 标注生词\n",
    "## 标注存储器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将一个训练好的标注器保存到一个文件以后重复使用\n",
    "output = open('t2.pkl', 'wb')\n",
    "dump(t2, output, -1)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "input = open('t2.pkl', 'rb')\n",
    "tagger = load(input)\n",
    "input.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'AT'),\n",
       " (\"board's\", 'NN$'),\n",
       " ('action', 'NN'),\n",
       " ('shows', 'NNS'),\n",
       " ('what', 'WDT'),\n",
       " ('free', 'JJ'),\n",
       " ('enterprise', 'NN'),\n",
       " ('is', 'BEZ'),\n",
       " ('up', 'RP'),\n",
       " ('against', 'IN'),\n",
       " ('in', 'IN'),\n",
       " ('our', 'PP$'),\n",
       " ('complex', 'JJ'),\n",
       " ('maze', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('regulatory', 'NN'),\n",
       " ('laws', 'NNS'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"The board's action shows what free enterprise\n",
    "...     is up against in our complex maze of regulatory laws .\"\"\"\n",
    "tokens = text.split()\n",
    "tagger.tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
